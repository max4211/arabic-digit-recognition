{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/02_intermediate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc(arg):\n",
    "    return mcolors.to_rgba(arg, alpha=0.6)\n",
    "\n",
    "def all_colors():\n",
    "    return [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\", \"tab:pink\", \"tab:gray\", \"tab:olive\", \"tab:cyan\",\n",
    "            \"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\",\n",
    "            \"limegreen\", \"cornflowerblue\", \"mediumblue\", \"darkorange\", \"maroon\", \"deepskyblue\", \"darkmagenta\"]\n",
    "\n",
    "def random_color():\n",
    "    pallette = all_colors()\n",
    "    return cc(random.choice(pallette))\n",
    "\n",
    "def get_color(index):\n",
    "    pallette = all_colors()\n",
    "    return cc(pallette[index])\n",
    "\n",
    "def all_lines():\n",
    "    return [\"-\", \"--\", \"-.\", \".\"]\n",
    "\n",
    "def all_markers():\n",
    "    return [\".\", \",\", \"o\", \"v\", \"^\", \"1\", \"8\", \"*\", \"H\", \"d\"]\n",
    "\n",
    "def random_marker():\n",
    "    return random.choice(all_markers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scatter_2D(matrix, labels, cluster_centers, n_clusters, digit, coeffs=[0, 1]):\n",
    "    \"\"\"Scatter plot of 2 dimensions of kmeans results\"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    clustered_matrix = parse_labels(matrix=matrix, labels=labels, n_clusters=n_clusters)\n",
    "    # for cluster in clustered_matrix:\n",
    "    for index in range(len(clustered_matrix)):\n",
    "        cluster = clustered_matrix[index]\n",
    "        xs = cluster[:, coeffs[0]]\n",
    "        ys = cluster[:, coeffs[1]]\n",
    "        ax.scatter(x=xs, y=ys, s=0.5, color=get_color(index=index), marker=random_marker())\n",
    "    \n",
    "    ax.set_xlabel(f\"MFCC {coeffs[0]}\")\n",
    "    ax.set_ylabel(f\"MFCC {coeffs[1]}\")\n",
    "    ax.set_title(f\"K-Means Result for Digit {digit} with {n_clusters} Clusters\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filter_arr(labels, cluster):\n",
    "    \"\"\"Create boolean flagged filter array to apply to filter np array\"\"\"\n",
    "    filter_arr = []\n",
    "    for label in labels:\n",
    "        if label == cluster:\n",
    "            filter_arr.append(True)\n",
    "        else:\n",
    "            filter_arr.append(False)\n",
    "    return filter_arr\n",
    "\n",
    "def parse_labels(matrix, labels, n_clusters):\n",
    "    \"\"\"Filter matrix and labels into clustered matrices for scatter plotting\"\"\"\n",
    "    clustered_matrix = []\n",
    "\n",
    "    for cluster in range(n_clusters):\n",
    "        filter_arr = create_filter_arr(labels=labels, cluster=cluster)\n",
    "        sub_matrix = matrix[filter_arr]\n",
    "        clustered_matrix.append(sub_matrix)\n",
    "\n",
    "    return clustered_matrix\n",
    "\n",
    "def analyze_cluster(matrix, labels, cluster_centers, n_clusters):\n",
    "    \"\"\"Compute covariance and pi value for gmm vars of clusters\"\"\"\n",
    "    covariance_matrix = []\n",
    "    pi_matrix = []\n",
    "\n",
    "    for cluster in range(n_clusters):\n",
    "        filter_arr = create_filter_arr(labels=labels, cluster=cluster)\n",
    "        sub_matrix = matrix[filter_arr]\n",
    "\n",
    "        pi = len(sub_matrix) / len(matrix)\n",
    "        covariance = np.cov(np.transpose(sub_matrix))\n",
    "\n",
    "        pi_matrix.append(pi)\n",
    "        covariance_matrix.append(covariance)\n",
    "        \n",
    "    return (covariance_matrix, pi_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussParams:\n",
    "    \"\"\" Gaussian Mixture Model object to encapsulate params \"\"\"\n",
    "    def __init__(self, u, pi, cov):\n",
    "        self.u = u\n",
    "        self.pi = pi\n",
    "        self.cov = cov\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"u: {self.u}\\npi: {self.pi}\\ncov: {self.cov}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(digits, clusters, model_coeffs, train_path):\n",
    "    \"\"\"\n",
    "    Create a gaussian mixture model from parameters\n",
    "    digits - max digit to train through\n",
    "    cluters - array of clutser counts (indexed by digit)\n",
    "    model_coeffs - range of model coefficients to use for modeling\n",
    "    train_path - relative path to training data\n",
    "    \"\"\"\n",
    "    gauss_results = []\n",
    "    for digit in range(digits):\n",
    "        # Read in train file and parse as dataframe\n",
    "        filename = f\"{train_path}{digit}.txt\"\n",
    "        df = pd.read_csv(filename, skip_blank_lines=True, delimiter=' ', header=None)\n",
    "        df.dropna(axis=0, inplace=True)\n",
    "\n",
    "        # Filter dataframe down to only model coefficient columns\n",
    "        df_filter = df.iloc[:, model_coeffs]\n",
    "        matrix = df_filter.values\n",
    "        n_clusters = clusters[digit]\n",
    "\n",
    "        # Apply kmeans on the matrix of values\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "        kmeans.fit(matrix)\n",
    "        labels = kmeans.labels_\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "        # Record the GMM results (u, pi, and cov)\n",
    "        cluster_covariance, cluster_pi = analyze_cluster(matrix=matrix, labels=labels, cluster_centers=cluster_centers, n_clusters=n_clusters)    \n",
    "        gauss = GaussParams(u=cluster_centers, pi=cluster_pi, cov=cluster_covariance)\n",
    "        gauss_results.append(gauss)\n",
    "\n",
    "        # Visualize the kmeans plot as scatter in 2D\n",
    "        # custom_scatter_2D(matrix=matrix, labels=labels, cluster_centers=cluster_centers, n_clusters=n_clusters, digit=digit, coeffs=PLOT_COEFFS)\n",
    "    return gauss_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pi_df(gauss_results):\n",
    "    \"\"\" Printing probability of ending up in each mixture\"\"\"\n",
    "    pi_vals = []\n",
    "    for index in range(len(gauss_results)):\n",
    "        result = gauss_results[index]\n",
    "        pi_vals.append(result.pi)\n",
    "\n",
    "    # print(f\"PI VALUES FOR GAUSS RESULTS (cluster result x digit)\")\n",
    "    pi_df = pd.DataFrame(pi_vals)\n",
    "    return pi_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dataframes(digit, write_path, read_path, stopwatch):\n",
    "    \"\"\"\n",
    "    Get all of the dataframes for a single digit \n",
    "    Use single_person data folder as intermediary for pandas read csv ease of use\n",
    "    \"\"\"\n",
    "    start_time = dt.now()\n",
    "    read_filename = f\"{read_path}{digit}.txt\"\n",
    "    write_filename = f\"{write_path}{digit}.txt\"\n",
    "\n",
    "    f = open(write_filename, \"w\")\n",
    "    line_count = 0\n",
    "\n",
    "    df_all = []\n",
    "\n",
    "    # Open file and build out data\n",
    "    with open(read_filename, \"r\") as file:\n",
    "        for line in file:\n",
    "            if len(line.strip()) != 0:\n",
    "                f.write(line)\n",
    "                line_count += 1\n",
    "            elif line_count > 0:\n",
    "                # Close file descriptor, read in written data, update dataframes\n",
    "                f.close()\n",
    "                df = pd.read_csv(write_filename, skip_blank_lines=True, delimiter=' ', header=None)\n",
    "                df_all.append(df)\n",
    "\n",
    "                # Reset line count and file descriptor for new dataframe parse\n",
    "                line_count = 0\n",
    "                f = open(write_filename, \"w\")\n",
    "\n",
    "    # Likely have one more (no missing line on final line)\n",
    "    if line_count > 0:\n",
    "        f.close()\n",
    "        df = pd.read_csv(write_filename, skip_blank_lines=True, delimiter=' ', header=None)\n",
    "        df_all.append(df)\n",
    "\n",
    "    end_time = dt.now()\n",
    "    total_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "    if (stopwatch):\n",
    "        print(f\"Parsed {len(df_all)} frames in {total_time} sec\")\n",
    "\n",
    "    return df_all\n",
    "     \n",
    "def print_summary(digit, total_time, correct, utterances):\n",
    "    \"\"\"Output summary from classification to console\"\"\"\n",
    "    accuracy = correct / utterances * 100\n",
    "    accuracy = round(accuracy, 3)\n",
    "    dt_format = \"%H:%M:%S\"\n",
    "    cur_time = dt.strftime(dt.now(), dt_format) \n",
    "    print(f\"#{digit}\\taccuracy: {accuracy}%\\tcorrect: {correct}\\tutterances: {utterances}\\ttotal_time: {round(total_time, 3)} sec\\tcur_time: {cur_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_dataframe(df, gauss_results, digits, model_coeffs):\n",
    "    \"\"\"\n",
    "    Classify a dataframe based on gaussian results\n",
    "    df - dataframe to classify\n",
    "    gauss_results - gmm mixture model results\n",
    "    digits - total digits to validate\n",
    "    model_coeffs - model coefficients (array)\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform classification on some test data\n",
    "    posterior_all = []\n",
    "    for d in range(digits):\n",
    "        \"\"\"Iterate over all digits (possible classifications\"\"\"\n",
    "        posterior_digit = 0\n",
    "\n",
    "        for n, row in df.iterrows():\n",
    "            \"\"\"Iterate over all n frames of the sample\"\"\"\n",
    "            frames_n = row.to_numpy()[model_coeffs]\n",
    "\n",
    "            sum_m = 0\n",
    "            result_m = gauss_results[d]\n",
    "            \"\"\"Iterate over all results from gmm parameters\"\"\"\n",
    "            cov, pi, u = result_m.cov, result_m.pi, result_m.u   \n",
    "\n",
    "            for m in range(len(u)):\n",
    "                \"\"\"Iterate over all m dimensions of mixture model\"\"\"\n",
    "                u_m = u[m]\n",
    "                cov_m = cov[m]\n",
    "                pi_m = pi[m]\n",
    "\n",
    "                y = multivariate_normal.pdf(x=frames_n, mean=u_m, cov=cov_m)\n",
    "                posterior_i = y * pi_m\n",
    "                sum_m += posterior_i\n",
    "\n",
    "            # end sum over all gauss components for digit\n",
    "            posterior_digit += np.log(sum_m)\n",
    "            \n",
    "            # circuit break on underflow, no longer needed with logpdf\n",
    "            # y = multivariate_normal.pdf(x=frames_n, mean=u_m, cov=cov_m)  # this causes underflow\n",
    "            if posterior_digit == 0:\n",
    "                sys.exit()\n",
    "\n",
    "        # TODO - normalize by the number of samples (is this necessary?)\n",
    "        # end product of all n frames\n",
    "        # if (debug):\n",
    "        #     print(f\"digit: {d}\\tposterior_digit: {posterior_digit}\")\n",
    "        posterior_all.append(posterior_digit)\n",
    "    \n",
    "    classification = posterior_all.index(max(posterior_all))\n",
    "    return (classification, posterior_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(classify_every, gauss_results, model_coeffs, digits):\n",
    "    \"\"\"\n",
    "    Using previously computed gauss results, test the model\n",
    "    classify_every - increase for speed (skip values)\n",
    "    gauss_results - gaussian mixture model parameters\n",
    "    model_coeffs - coefficients from model used in generation\n",
    "    digits - total digits to train on\n",
    "    \"\"\"\n",
    "\n",
    "    test_read_path = f\"{DATA_PATH}test_digits/test_0\"\n",
    "    test_write_path = f\"{DATA_PATH}single_person/test_0\"\n",
    "\n",
    "    classify_results = []\n",
    "    summary_lists = []\n",
    "    for digit in range(digits):\n",
    "        total_classified = 0\n",
    "        correct = 0\n",
    "        df_all = get_all_dataframes(digit=digit, write_path=test_write_path, read_path=test_read_path, stopwatch=False)\n",
    "        classify_digit = [0]*digits\n",
    "\n",
    "        index = 0\n",
    "        start_time = dt.now()\n",
    "        for df in df_all:\n",
    "            if index % classify_every == 0:\n",
    "                (classification, posterior_all) = classify_dataframe(df=df, gauss_results=gauss_results, digits=digits, model_coeffs=model_coeffs) \n",
    "                total_classified += 1\n",
    "                classify_digit[classification] += 1\n",
    "                if classification == digit:\n",
    "                    correct += 1\n",
    "            index += 1\n",
    "\n",
    "        classify_results.append(classify_digit)\n",
    "\n",
    "        end_time = dt.now()\n",
    "        total_time = round((end_time - start_time).total_seconds(), 3)\n",
    "        accuracy = round(correct / total_classified * 100, 3)\n",
    "        # total_time = f\"{total_time} sec\"\n",
    "        # accuracy = f\"{accuracy} %\"\n",
    "        summary = [digit, accuracy, correct, total_classified, total_time]\n",
    "        summary_lists.append(summary)\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_lists, columns=[\"Digit\", \"Accuracy (%)\", \"Correct\", \"Classified\", \"Time (s)\"])\n",
    "    classify_df = pd.DataFrame(classify_results)\n",
    "\n",
    "    return (summary_df, classify_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_files(use_coeffs, num_clusters):\n",
    "    return f\"{use_coeffs}mfcc_{num_clusters}clust\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all relative file paths to actually get files\n",
    "TRAIN_PATH = f\"{DATA_PATH}train_digits/train_0\"\n",
    "TEST_PATH = f\"{DATA_PATH}test_digits/test_0\"\n",
    "WRITE_PATH = f\"../../data/03_results/\"\n",
    "\n",
    "PI_SUFFIX = \"_pi.csv\"\n",
    "CONF_SUFFIX = \"_conf.csv\"\n",
    "RESULTS_SUFFIX = \"_results.csv\"\n",
    "SUMMARY_SUFFIX = \"_summary.csv\"\n",
    "\n",
    "DIGITS = 10\n",
    "PLOT_COEFFS = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_coeffs = 7\n",
    "# digits = 10\n",
    "# model_coeffs = range(use_coeffs)\n",
    "# num_clusters = 3\n",
    "# clusters = [num_clusters]*digits\n",
    "# classify_every = 5\n",
    "\n",
    "# MAX_CLUSTERS = 8\n",
    "# for num_clusters in range(1,MAX_CLUSTERS):\n",
    "#     clusters = [num_clusters]*digits\n",
    "\n",
    "#     # Run model on parameters\n",
    "#     gauss_results = create_model(digits=digits, clusters=clusters, model_coeffs=model_coeffs, train_path=TRAIN_PATH)\n",
    "#     (summary_df, classify_df) = test_model(classify_every=classify_every, gauss_results=gauss_results, model_coeffs=model_coeffs, digits=digits)\n",
    "#     pi_df = get_pi_df(gauss_results=gauss_results)\n",
    "\n",
    "#     # Write output files and send useful printout\n",
    "#     prefix = name_files(use_coeffs=use_coeffs, num_clusters=num_clusters)\n",
    "#     pi_filename = f\"{WRITE_PATH}{prefix}{PI_SUFFIX}\"\n",
    "#     conf_filename = f\"{WRITE_PATH}{prefix}{CONF_SUFFIX}\"\n",
    "#     results_filename = f\"{WRITE_PATH}{prefix}{RESULTS_SUFFIX}\"\n",
    "#     # summary_filename = f\"{WRITE_PATH}{prefix}{SUMMARY_SUFFIX}\"\n",
    "\n",
    "#     # TODO write to datafile\n",
    "#     print(f\"{prefix}: \\n{summary_df.mean(axis=0)}\\n\")\n",
    "#     summary_df.to_csv(results_filename)\n",
    "#     classify_df.to_csv(conf_filename)\n",
    "#     pi_df.to_csv(pi_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_COEFFS = 11\n",
    "# digits = 10\n",
    "# model_coeffs = range(use_coeffs)\n",
    "# num_clusters = 4\n",
    "# clusters = [num_clusters]*digits\n",
    "# classify_every = 5\n",
    "\n",
    "# for use_coeffs in range(1,MAX_COEFFS):\n",
    "#     model_coeffs = range(use_coeffs)\n",
    "\n",
    "#     # Run model on parameters\n",
    "#     gauss_results = create_model(digits=digits, clusters=clusters, model_coeffs=model_coeffs, train_path=TRAIN_PATH)\n",
    "#     (summary_df, classify_df) = test_model(classify_every=classify_every, gauss_results=gauss_results, model_coeffs=model_coeffs, digits=digits)\n",
    "#     pi_df = get_pi_df(gauss_results=gauss_results)\n",
    "\n",
    "#     # Write output files and send useful printout\n",
    "#     prefix = name_files(use_coeffs=use_coeffs, num_clusters=num_clusters)\n",
    "#     pi_filename = f\"{WRITE_PATH}{prefix}{PI_SUFFIX}\"\n",
    "#     conf_filename = f\"{WRITE_PATH}{prefix}{CONF_SUFFIX}\"\n",
    "#     results_filename = f\"{WRITE_PATH}{prefix}{RESULTS_SUFFIX}\"\n",
    "#     # summary_filename = f\"{WRITE_PATH}{prefix}{SUMMARY_SUFFIX}\"\n",
    "\n",
    "#     # Useful printout for debug, save files\n",
    "#     print(f\"{prefix}: \\n{summary_df.mean(axis=0)}\\n\")\n",
    "#     summary_df.to_csv(results_filename)\n",
    "#     classify_df.to_csv(conf_filename)\n",
    "#     pi_df.to_csv(pi_filename)\n",
    "\n",
    "#     txt_out = f\"{WRITE_PATH}{num_clusters}clust_out.txt\"\n",
    "#     f = open(txt_out, \"a\")\n",
    "#     f.write(f\"{prefix}: \\n{summary_df.mean(axis=0)}\\n\\n\")\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_accuracy = summary_df[\"Accuracy (%)\"].mean(axis=0)\n",
    "# print(f\"Average Accuracy: {avg_accuracy} %\")\n",
    "\n",
    "# avg_time = summary_df[\"Time (s)\"].mean(axis=0)\n",
    "# print(f\"Average Time (for classified utterances): {avg_time} sec\")\n",
    "\n",
    "# tot_time = summary_df[\"Time (s)\"].sum(axis=0)\n",
    "# print(f\"Total Time: {tot_time} sec\")\n",
    "\n",
    "# tot_classified = summary_df[\"Classified\"].sum(axis=0)\n",
    "# print(f\"Total Classified: {tot_classified}\")\n",
    "\n",
    "# avg_time_utter = tot_time / tot_classified\n",
    "# print(f\"Average Time (per utterance): {round(avg_time_utter, 3)} sec\")\n",
    "\n",
    "# # TODO - mesh grid of accuracy/time per utterance over mfcc/clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshResults:\n",
    "    \"\"\" Gaussian Mixture Model object to encapsulate params \"\"\"\n",
    "    def __init__(self, accuracy, time, conf, summary, coeffs, clusters):\n",
    "        self.accuracy = round(accuracy, 3)\n",
    "        self.time = round(time, 3)\n",
    "        self.conf = conf\n",
    "        self.summary = summary\n",
    "        self.coeffs = coeffs\n",
    "        self.clusters = clusters\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.coeffs} MFFCS\\t{self.clusters} clusters\\t{self.accuracy} %\\t{self.time} seconds/utterance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_time(summary_df):\n",
    "    \"\"\"\n",
    "    Get accuracy and time from summary dataframe\n",
    "    \"\"\"\n",
    "    accuracy = summary_df[\"Accuracy (%)\"].mean(axis=0)\n",
    "    tot_time = summary_df[\"Time (s)\"].sum(axis=0)\n",
    "    tot_classified = summary_df[\"Classified\"].sum(axis=0)\n",
    "    time = tot_time / tot_classified\n",
    "    return (accuracy, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - meshgrid and save mesh_results as pickle\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def load_serial(filename):\n",
    "    \"\"\"\n",
    "    Load serialized object and return\n",
    "    \"\"\"\n",
    "    pickle_in = open(filename, \"rb\")\n",
    "    obj = pickle.load(pickle_in)\n",
    "\n",
    "    size = os.stat(filename).st_size\n",
    "    print(f\"loaded {size} bytes\")\n",
    "\n",
    "    return obj\n",
    "\n",
    "def serialize_mesh(obj, filename):\n",
    "    \"\"\"\n",
    "    Use pickle to serialize object and dump in output directory\n",
    "    \"\"\"\n",
    "    pickle_out = open(filename, \"wb\")\n",
    "    pickle.dump(obj, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    size = os.stat(filename).st_size\n",
    "    print(f\"dumped {size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1mfcc_1clust: \n",
      "Digit             4.5000\n",
      "Accuracy (%)     28.6323\n",
      "Correct          31.5000\n",
      "Classified      110.1000\n",
      "Time (s)          7.6906\n",
      "dtype: float64\n",
      "\n",
      "1mfcc_2clust: \n",
      "Digit             4.5000\n",
      "Accuracy (%)     33.9936\n",
      "Correct          37.4000\n",
      "Classified      110.1000\n",
      "Time (s)         10.9645\n",
      "dtype: float64\n",
      "\n",
      "1mfcc_3clust: \n",
      "Digit             4.5000\n",
      "Accuracy (%)     32.1744\n",
      "Correct          35.4000\n",
      "Classified      110.1000\n",
      "Time (s)         13.7742\n",
      "dtype: float64\n",
      "\n",
      "1mfcc_4clust: \n",
      "Digit             4.5000\n",
      "Accuracy (%)     32.3587\n",
      "Correct          35.6000\n",
      "Classified      110.1000\n",
      "Time (s)         16.3172\n",
      "dtype: float64\n",
      "\n",
      "1mfcc_5clust: \n",
      "Digit             4.5000\n",
      "Accuracy (%)     34.4496\n",
      "Correct          37.9000\n",
      "Classified      110.1000\n",
      "Time (s)         20.1641\n",
      "dtype: float64\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-64f543b651e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Run model on parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mgauss_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_coeffs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_coeffs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTRAIN_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0msummary_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassify_df\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassify_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassify_every\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgauss_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgauss_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_coeffs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_coeffs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mpi_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_pi_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgauss_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgauss_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-6aef440943f6>\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(classify_every, gauss_results, model_coeffs, digits)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mclassify_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposterior_all\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgauss_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgauss_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdigits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_coeffs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_coeffs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0mtotal_classified\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mclassify_digit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-288c22f87ca6>\u001b[0m in \u001b[0;36mclassify_dataframe\u001b[1;34m(df, gauss_results, digits, model_coeffs)\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mpi_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframes_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mu_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcov_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                 \u001b[0mposterior_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpi_m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0msum_m\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mposterior_i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36mpdf\u001b[1;34m(self, x, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_quantiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mpsd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_PSD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_singular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpsd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpsd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_pdet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpsd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_squeeze_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, M, cond, rcond, lower, check_finite, allow_singular)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;31m# Note that eigh takes care of array conversion, chkfinite,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# and assertion that the matrix is square.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_eigvalsh_to_eps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\scipy\\linalg\\decomp.py\u001b[0m in \u001b[0;36meigh\u001b[1;34m(a, b, lower, eigvals_only, overwrite_a, overwrite_b, turbo, eigvals, type, check_finite, subset_by_index, subset_by_value, driver)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[0mdrv_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'lower'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'compute_v'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_job\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"N\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdrv_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlwork_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Generalized problem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAX_COEFFS = 13\n",
    "MAX_CLUSTERS = 10\n",
    "\n",
    "digits = 10\n",
    "classify_every = 2\n",
    "\n",
    "mesh_all = []\n",
    "\n",
    "for use_coeffs in range(1,MAX_COEFFS+1):\n",
    "    model_coeffs = range(use_coeffs)\n",
    "    mesh_row = []\n",
    "\n",
    "    for num_clusters in range(1,MAX_CLUSTERS+1):\n",
    "        clusters = [num_clusters]*digits\n",
    "        \n",
    "        # Run model on parameters\n",
    "        gauss_results = create_model(digits=digits, clusters=clusters, model_coeffs=model_coeffs, train_path=TRAIN_PATH)\n",
    "        (summary_df, classify_df) = test_model(classify_every=classify_every, gauss_results=gauss_results, model_coeffs=model_coeffs, digits=digits)\n",
    "        pi_df = get_pi_df(gauss_results=gauss_results)\n",
    "\n",
    "        # Pump results into mesh grid\n",
    "        (accuracy, time) = get_accuracy_time(summary_df=summary_df)\n",
    "        mesh_results = MeshResults(accuracy=accuracy, time=time, conf=classify_df, summary=summary_df, coeffs=use_coeffs, clusters=num_clusters) \n",
    "        mesh_row.append(mesh_results)\n",
    "\n",
    "        # Write output files and send useful printout\n",
    "        prefix = name_files(use_coeffs=use_coeffs, num_clusters=num_clusters)\n",
    "\n",
    "        # Useful printout for debug, save files\n",
    "        print(f\"{prefix}: \\n{summary_df.mean(axis=0)}\\n\")\n",
    "\n",
    "    # end iteration over cluster count\n",
    "    mesh_all.append(mesh_row)\n",
    "\n",
    "    # Serialize periodically so we don't lose data\n",
    "    SERIAL_PATH = \"../../data/04_serial/\"\n",
    "    prefix = name_files(use_coeffs=MAX_COEFFS, num_clusters=MAX_CLUSTERS)\n",
    "    filename = f\"{SERIAL_PATH}{prefix}.pickle\" # \"../../data/04_serial/clust_test.pickle\"\n",
    "    serialize_mesh(obj=mesh_all, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dumped 8114 bytes\nloaded 8114 bytes\n1 MFFCS\t1 clusters\t28.848 %\t0.059 seconds/utterance\n1 MFFCS\t2 clusters\t32.707 %\t0.102 seconds/utterance\n2 MFFCS\t1 clusters\t41.05 %\t0.064 seconds/utterance\n2 MFFCS\t2 clusters\t43.551 %\t0.103 seconds/utterance\n"
     ]
    }
   ],
   "source": [
    "# Perform final serialization on all objects (not necessary)\n",
    "SERIAL_PATH = \"../../data/04_serial/\"\n",
    "\n",
    "prefix = name_files(use_coeffs=MAX_COEFFS, num_clusters=MAX_CLUSTERS)\n",
    "filename = f\"{SERIAL_PATH}{prefix}.pickle\" # \"../../data/04_serial/clust_test.pickle\"\n",
    "serialize_mesh(obj=mesh_all, filename=filename)\n",
    "result = load_serial(filename)\n",
    "\n",
    "# Testing printout of serialized load of results\n",
    "for row in result:\n",
    "    for col in row:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}