{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/02_intermediate/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc(arg):\n",
    "    return mcolors.to_rgba(arg, alpha=0.6)\n",
    "\n",
    "def all_colors():\n",
    "    return [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\", \"tab:pink\", \"tab:gray\", \"tab:olive\", \"tab:cyan\",\n",
    "            \"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\",\n",
    "            \"limegreen\", \"cornflowerblue\", \"mediumblue\", \"darkorange\", \"maroon\", \"deepskyblue\", \"darkmagenta\"]\n",
    "\n",
    "def random_color():\n",
    "    pallette = all_colors()\n",
    "    return cc(random.choice(pallette))\n",
    "\n",
    "def get_color(index):\n",
    "    pallette = all_colors()\n",
    "    return cc(pallette[index])\n",
    "\n",
    "def all_lines():\n",
    "    return [\"-\", \"--\", \"-.\", \".\"]\n",
    "\n",
    "def all_markers():\n",
    "    return [\".\", \",\", \"o\", \"v\", \"^\", \"1\", \"8\", \"*\", \"H\", \"d\"]\n",
    "\n",
    "def random_marker():\n",
    "    return random.choice(all_markers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scatter_2D(matrix, labels, cluster_centers, n_clusters, digit, coeffs=[0, 1]):\n",
    "    \"\"\"Scatter plot of 2 dimensions of kmeans results\"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    clustered_matrix = parse_labels(matrix=matrix, labels=labels, n_clusters=n_clusters)\n",
    "    # for cluster in clustered_matrix:\n",
    "    for index in range(len(clustered_matrix)):\n",
    "        cluster = clustered_matrix[index]\n",
    "        xs = cluster[:, coeffs[0]]\n",
    "        ys = cluster[:, coeffs[1]]\n",
    "        ax.scatter(x=xs, y=ys, s=0.5, color=get_color(index=index), marker=random_marker())\n",
    "    \n",
    "    ax.set_xlabel(f\"MFCC {coeffs[0]}\")\n",
    "    ax.set_ylabel(f\"MFCC {coeffs[1]}\")\n",
    "    ax.set_title(f\"K-Means Result for Digit {digit} with {n_clusters} Clusters\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filter_arr(labels, cluster):\n",
    "    \"\"\"Create boolean flagged filter array to apply to filter np array\"\"\"\n",
    "    filter_arr = []\n",
    "    for label in labels:\n",
    "        if label == cluster:\n",
    "            filter_arr.append(True)\n",
    "        else:\n",
    "            filter_arr.append(False)\n",
    "    return filter_arr\n",
    "\n",
    "def parse_labels(matrix, labels, n_clusters):\n",
    "    \"\"\"Filter matrix and labels into clustered matrices for scatter plotting\"\"\"\n",
    "    clustered_matrix = []\n",
    "\n",
    "    for cluster in range(n_clusters):\n",
    "        filter_arr = create_filter_arr(labels=labels, cluster=cluster)\n",
    "        sub_matrix = matrix[filter_arr]\n",
    "        clustered_matrix.append(sub_matrix)\n",
    "\n",
    "    return clustered_matrix\n",
    "\n",
    "def analyze_cluster(matrix, labels, cluster_centers, n_clusters):\n",
    "    \"\"\"Compute covariance and pi value for gmm vars of clusters\"\"\"\n",
    "    covariance_matrix = []\n",
    "    pi_matrix = []\n",
    "\n",
    "    for cluster in range(n_clusters):\n",
    "        filter_arr = create_filter_arr(labels=labels, cluster=cluster)\n",
    "        sub_matrix = matrix[filter_arr]\n",
    "\n",
    "        pi = len(sub_matrix) / len(matrix)\n",
    "        covariance = np.cov(np.transpose(sub_matrix))\n",
    "\n",
    "        pi_matrix.append(pi)\n",
    "        covariance_matrix.append(covariance)\n",
    "        \n",
    "    return (covariance_matrix, pi_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussParams:\n",
    "    \"\"\" Gaussian Mixture Model object to encapsulate params \"\"\"\n",
    "    def __init__(self, u, pi, cov):\n",
    "        self.u = u\n",
    "        self.pi = pi\n",
    "        self.cov = cov\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"u: {self.u}\\npi: {self.pi}\\ncov: {self.cov}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(digits, clusters, model_coeffs, train_path):\n",
    "    \"\"\"\n",
    "    Create a gaussian mixture model from parameters\n",
    "    digits - max digit to train through\n",
    "    cluters - array of clutser counts (indexed by digit)\n",
    "    model_coeffs - range of model coefficients to use for modeling\n",
    "    train_path - relative path to training data\n",
    "    \"\"\"\n",
    "    gauss_results = []\n",
    "    for digit in range(digits):\n",
    "        # Read in train file and parse as dataframe\n",
    "        filename = f\"{train_path}{digit}.txt\"\n",
    "        df = pd.read_csv(filename, skip_blank_lines=True, delimiter=' ', header=None)\n",
    "        df.dropna(axis=0, inplace=True)\n",
    "\n",
    "        # Filter dataframe down to only model coefficient columns\n",
    "        df_filter = df.iloc[:, model_coeffs]\n",
    "        matrix = df_filter.values\n",
    "        n_clusters = clusters[digit]\n",
    "\n",
    "        # Apply kmeans on the matrix of values\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "        kmeans.fit(matrix)\n",
    "        labels = kmeans.labels_\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "        # Record the GMM results (u, pi, and cov)\n",
    "        cluster_covariance, cluster_pi = analyze_cluster(matrix=matrix, labels=labels, cluster_centers=cluster_centers, n_clusters=n_clusters)    \n",
    "        gauss = GaussParams(u=cluster_centers, pi=cluster_pi, cov=cluster_covariance)\n",
    "        gauss_results.append(gauss)\n",
    "\n",
    "        # Visualize the kmeans plot as scatter in 2D\n",
    "        # custom_scatter_2D(matrix=matrix, labels=labels, cluster_centers=cluster_centers, n_clusters=n_clusters, digit=digit, coeffs=PLOT_COEFFS)\n",
    "    return gauss_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pi_df(gauss_results):\n",
    "    \"\"\" Printing probability of ending up in each mixture\"\"\"\n",
    "    pi_vals = []\n",
    "    for index in range(len(gauss_results)):\n",
    "        result = gauss_results[index]\n",
    "        pi_vals.append(result.pi)\n",
    "\n",
    "    # print(f\"PI VALUES FOR GAUSS RESULTS (cluster result x digit)\")\n",
    "    pi_df = pd.DataFrame(pi_vals)\n",
    "    return pi_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_dataframes(digit, write_path, read_path, stopwatch):\n",
    "    \"\"\"\n",
    "    Get all of the dataframes for a single digit \n",
    "    Use single_person data folder as intermediary for pandas read csv ease of use\n",
    "    \"\"\"\n",
    "    start_time = dt.now()\n",
    "    read_filename = f\"{read_path}{digit}.txt\"\n",
    "    write_filename = f\"{write_path}{digit}.txt\"\n",
    "\n",
    "    f = open(write_filename, \"w\")\n",
    "    line_count = 0\n",
    "\n",
    "    df_all = []\n",
    "\n",
    "    # Open file and build out data\n",
    "    with open(read_filename, \"r\") as file:\n",
    "        for line in file:\n",
    "            if len(line.strip()) != 0:\n",
    "                f.write(line)\n",
    "                line_count += 1\n",
    "            elif line_count > 0:\n",
    "                # Close file descriptor, read in written data, update dataframes\n",
    "                f.close()\n",
    "                df = pd.read_csv(write_filename, skip_blank_lines=True, delimiter=' ', header=None)\n",
    "                df_all.append(df)\n",
    "\n",
    "                # Reset line count and file descriptor for new dataframe parse\n",
    "                line_count = 0\n",
    "                f = open(write_filename, \"w\")\n",
    "\n",
    "    # Likely have one more (no missing line on final line)\n",
    "    if line_count > 0:\n",
    "        f.close()\n",
    "        df = pd.read_csv(write_filename, skip_blank_lines=True, delimiter=' ', header=None)\n",
    "        df_all.append(df)\n",
    "\n",
    "    end_time = dt.now()\n",
    "    total_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "    if (stopwatch):\n",
    "        print(f\"Parsed {len(df_all)} frames in {total_time} sec\")\n",
    "\n",
    "    return df_all\n",
    "     \n",
    "def print_summary(digit, total_time, correct, utterances):\n",
    "    \"\"\"Output summary from classification to console\"\"\"\n",
    "    accuracy = correct / utterances * 100\n",
    "    accuracy = round(accuracy, 3)\n",
    "    dt_format = \"%H:%M:%S\"\n",
    "    cur_time = dt.strftime(dt.now(), dt_format) \n",
    "    print(f\"#{digit}\\taccuracy: {accuracy}%\\tcorrect: {correct}\\tutterances: {utterances}\\ttotal_time: {round(total_time, 3)} sec\\tcur_time: {cur_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_dataframe(df, gauss_results, digits, model_coeffs):\n",
    "    \"\"\"\n",
    "    Classify a dataframe based on gaussian results\n",
    "    df - dataframe to classify\n",
    "    gauss_results - gmm mixture model results\n",
    "    digits - total digits to validate\n",
    "    model_coeffs - model coefficients (array)\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform classification on some test data\n",
    "    posterior_all = []\n",
    "    for d in range(digits):\n",
    "        \"\"\"Iterate over all digits (possible classifications\"\"\"\n",
    "        posterior_digit = 0\n",
    "\n",
    "        for n, row in df.iterrows():\n",
    "            \"\"\"Iterate over all n frames of the sample\"\"\"\n",
    "            frames_n = row.to_numpy()[model_coeffs]\n",
    "\n",
    "            sum_m = 0\n",
    "            result_m = gauss_results[d]\n",
    "            \"\"\"Iterate over all results from gmm parameters\"\"\"\n",
    "            cov, pi, u = result_m.cov, result_m.pi, result_m.u   \n",
    "\n",
    "            for m in range(len(u)):\n",
    "                \"\"\"Iterate over all m dimensions of mixture model\"\"\"\n",
    "                u_m = u[m]\n",
    "                cov_m = cov[m]\n",
    "                pi_m = pi[m]\n",
    "\n",
    "                y = multivariate_normal.pdf(x=frames_n, mean=u_m, cov=cov_m)\n",
    "                posterior_i = y * pi_m\n",
    "                sum_m += posterior_i\n",
    "\n",
    "            # end sum over all gauss components for digit\n",
    "            posterior_digit += np.log(sum_m)\n",
    "            \n",
    "            # circuit break on underflow, no longer needed with logpdf\n",
    "            # y = multivariate_normal.pdf(x=frames_n, mean=u_m, cov=cov_m)  # this causes underflow\n",
    "            if posterior_digit == 0:\n",
    "                sys.exit()\n",
    "\n",
    "        # TODO - normalize by the number of samples (is this necessary?)\n",
    "        # end product of all n frames\n",
    "        # if (debug):\n",
    "        #     print(f\"digit: {d}\\tposterior_digit: {posterior_digit}\")\n",
    "        posterior_all.append(posterior_digit)\n",
    "    \n",
    "    classification = posterior_all.index(max(posterior_all))\n",
    "    return (classification, posterior_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(classify_every, gauss_results, model_coeffs, digits):\n",
    "    \"\"\"\n",
    "    Using previously computed gauss results, test the model\n",
    "    classify_every - increase for speed (skip values)\n",
    "    gauss_results - gaussian mixture model parameters\n",
    "    model_coeffs - coefficients from model used in generation\n",
    "    digits - total digits to train on\n",
    "    \"\"\"\n",
    "\n",
    "    test_read_path = f\"{DATA_PATH}test_digits/test_0\"\n",
    "    test_write_path = f\"{DATA_PATH}single_person/test_0\"\n",
    "\n",
    "    classify_results = []\n",
    "    summary_lists = []\n",
    "    for digit in range(digits):\n",
    "        total_classified = 0\n",
    "        correct = 0\n",
    "        df_all = get_all_dataframes(digit=digit, write_path=test_write_path, read_path=test_read_path, stopwatch=False)\n",
    "        classify_digit = [0]*digits\n",
    "\n",
    "        index = 0\n",
    "        start_time = dt.now()\n",
    "        for df in df_all:\n",
    "            if index % classify_every == 0:\n",
    "                (classification, posterior_all) = classify_dataframe(df=df, gauss_results=gauss_results, digits=digits, model_coeffs=model_coeffs) \n",
    "                total_classified += 1\n",
    "                classify_digit[classification] += 1\n",
    "                if classification == digit:\n",
    "                    correct += 1\n",
    "            index += 1\n",
    "\n",
    "        classify_results.append(classify_digit)\n",
    "\n",
    "        end_time = dt.now()\n",
    "        total_time = round((end_time - start_time).total_seconds(), 3)\n",
    "        accuracy = round(correct / total_classified * 100, 3)\n",
    "        # total_time = f\"{total_time} sec\"\n",
    "        # accuracy = f\"{accuracy} %\"\n",
    "        summary = [digit, accuracy, correct, total_classified, total_time]\n",
    "        summary_lists.append(summary)\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_lists, columns=[\"Digit\", \"Accuracy (%)\", \"Correct\", \"Classified\", \"Time (s)\"])\n",
    "    classify_df = pd.DataFrame(classify_results)\n",
    "\n",
    "    return (summary_df, classify_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_files(use_coeffs, num_clusters):\n",
    "    return f\"{use_coeffs}mfcc_{num_clusters}clust\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all relative file paths to actually get files\n",
    "TRAIN_PATH = f\"{DATA_PATH}train_digits/train_0\"\n",
    "TEST_PATH = f\"{DATA_PATH}test_digits/test_0\"\n",
    "WRITE_PATH = f\"../../data/03_results/\"\n",
    "\n",
    "PI_SUFFIX = \"_pi.csv\"\n",
    "CONF_SUFFIX = \"_conf.csv\"\n",
    "RESULTS_SUFFIX = \"_results.csv\"\n",
    "SUMMARY_SUFFIX = \"_summary.csv\"\n",
    "\n",
    "DIGITS = 10\n",
    "PLOT_COEFFS = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7mfcc_1clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    70.7677\n",
      "Correct         31.2000\n",
      "Classified      44.1000\n",
      "Time (s)         5.9973\n",
      "dtype: float64\n",
      "\n",
      "7mfcc_2clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    79.1363\n",
      "Correct         34.9000\n",
      "Classified      44.1000\n",
      "Time (s)         8.8299\n",
      "dtype: float64\n",
      "\n",
      "7mfcc_3clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    79.8183\n",
      "Correct         35.2000\n",
      "Classified      44.1000\n",
      "Time (s)        11.8460\n",
      "dtype: float64\n",
      "\n",
      "7mfcc_4clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    80.2576\n",
      "Correct         35.4000\n",
      "Classified      44.1000\n",
      "Time (s)        14.4753\n",
      "dtype: float64\n",
      "\n",
      "7mfcc_5clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    78.9041\n",
      "Correct         34.8000\n",
      "Classified      44.1000\n",
      "Time (s)        18.3012\n",
      "dtype: float64\n",
      "\n",
      "7mfcc_6clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    78.7020\n",
      "Correct         34.7000\n",
      "Classified      44.1000\n",
      "Time (s)        22.5781\n",
      "dtype: float64\n",
      "\n",
      "7mfcc_7clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    80.7271\n",
      "Correct         35.6000\n",
      "Classified      44.1000\n",
      "Time (s)        26.2171\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_coeffs = 7\n",
    "digits = 10\n",
    "model_coeffs = range(use_coeffs)\n",
    "num_clusters = 3\n",
    "clusters = [num_clusters]*digits\n",
    "classify_every = 5\n",
    "\n",
    "MAX_CLUSTERS = 8\n",
    "for num_clusters in range(1,MAX_CLUSTERS):\n",
    "    clusters = [num_clusters]*digits\n",
    "\n",
    "    # Run model on parameters\n",
    "    gauss_results = create_model(digits=digits, clusters=clusters, model_coeffs=model_coeffs, train_path=TRAIN_PATH)\n",
    "    (summary_df, classify_df) = test_model(classify_every=classify_every, gauss_results=gauss_results, model_coeffs=model_coeffs, digits=digits)\n",
    "    pi_df = get_pi_df(gauss_results=gauss_results)\n",
    "\n",
    "    # Write output files and send useful printout\n",
    "    prefix = name_files(use_coeffs=use_coeffs, num_clusters=num_clusters)\n",
    "    pi_filename = f\"{WRITE_PATH}{prefix}{PI_SUFFIX}\"\n",
    "    conf_filename = f\"{WRITE_PATH}{prefix}{CONF_SUFFIX}\"\n",
    "    results_filename = f\"{WRITE_PATH}{prefix}{RESULTS_SUFFIX}\"\n",
    "    # summary_filename = f\"{WRITE_PATH}{prefix}{SUMMARY_SUFFIX}\"\n",
    "\n",
    "    # TODO write to datafile\n",
    "    print(f\"{prefix}: \\n{summary_df.mean(axis=0)}\\n\")\n",
    "    summary_df.to_csv(results_filename)\n",
    "    classify_df.to_csv(conf_filename)\n",
    "    pi_df.to_csv(pi_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1mfcc_4clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    33.1515\n",
      "Correct         14.6000\n",
      "Classified      44.1000\n",
      "Time (s)         6.2872\n",
      "dtype: float64\n",
      "\n",
      "2mfcc_4clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    43.0709\n",
      "Correct         19.0000\n",
      "Classified      44.1000\n",
      "Time (s)         7.6714\n",
      "dtype: float64\n",
      "\n",
      "3mfcc_4clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    69.8385\n",
      "Correct         30.8000\n",
      "Classified      44.1000\n",
      "Time (s)         7.2889\n",
      "dtype: float64\n",
      "\n",
      "4mfcc_4clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    72.0910\n",
      "Correct         31.8000\n",
      "Classified      44.1000\n",
      "Time (s)         7.7127\n",
      "dtype: float64\n",
      "\n",
      "5mfcc_4clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    75.0505\n",
      "Correct         33.1000\n",
      "Classified      44.1000\n",
      "Time (s)         8.3568\n",
      "dtype: float64\n",
      "\n",
      "6mfcc_4clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    76.8486\n",
      "Correct         33.9000\n",
      "Classified      44.1000\n",
      "Time (s)        13.1460\n",
      "dtype: float64\n",
      "\n",
      "7mfcc_4clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    80.2576\n",
      "Correct         35.4000\n",
      "Classified      44.1000\n",
      "Time (s)        14.8867\n",
      "dtype: float64\n",
      "\n",
      "8mfcc_4clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    85.0203\n",
      "Correct         37.5000\n",
      "Classified      44.1000\n",
      "Time (s)        16.9601\n",
      "dtype: float64\n",
      "\n",
      "9mfcc_4clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    84.5656\n",
      "Correct         37.3000\n",
      "Classified      44.1000\n",
      "Time (s)        18.4701\n",
      "dtype: float64\n",
      "\n",
      "10mfcc_4clust: \n",
      "Digit            4.5000\n",
      "Accuracy (%)    85.7021\n",
      "Correct         37.8000\n",
      "Classified      44.1000\n",
      "Time (s)        20.4073\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_COEFFS = 11\n",
    "digits = 10\n",
    "model_coeffs = range(use_coeffs)\n",
    "num_clusters = 4\n",
    "clusters = [num_clusters]*digits\n",
    "classify_every = 5\n",
    "\n",
    "for use_coeffs in range(1,MAX_COEFFS):\n",
    "    model_coeffs = range(use_coeffs)\n",
    "\n",
    "    # Run model on parameters\n",
    "    gauss_results = create_model(digits=digits, clusters=clusters, model_coeffs=model_coeffs, train_path=TRAIN_PATH)\n",
    "    (summary_df, classify_df) = test_model(classify_every=classify_every, gauss_results=gauss_results, model_coeffs=model_coeffs, digits=digits)\n",
    "    pi_df = get_pi_df(gauss_results=gauss_results)\n",
    "\n",
    "    # Write output files and send useful printout\n",
    "    prefix = name_files(use_coeffs=use_coeffs, num_clusters=num_clusters)\n",
    "    pi_filename = f\"{WRITE_PATH}{prefix}{PI_SUFFIX}\"\n",
    "    conf_filename = f\"{WRITE_PATH}{prefix}{CONF_SUFFIX}\"\n",
    "    results_filename = f\"{WRITE_PATH}{prefix}{RESULTS_SUFFIX}\"\n",
    "    # summary_filename = f\"{WRITE_PATH}{prefix}{SUMMARY_SUFFIX}\"\n",
    "\n",
    "    # Useful printout for debug, save files\n",
    "    print(f\"{prefix}: \\n{summary_df.mean(axis=0)}\\n\")\n",
    "    summary_df.to_csv(results_filename)\n",
    "    classify_df.to_csv(conf_filename)\n",
    "    pi_df.to_csv(pi_filename)\n",
    "\n",
    "    txt_out = f\"{WRITE_PATH}{num_clusters}clust_out.txt\"\n",
    "    f = open(txt_out, \"w\")\n",
    "    f.write(f\"{prefix}: \\n{summary_df.mean(axis=0)}\\n\")\n",
    "    f.close()"
   ]
  }
 ]
}